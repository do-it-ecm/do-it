<!doctype html><html lang="fr"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width,initial-scale=1"><meta name="robots" content="index, follow"><link rel="canonical" href="https://do-it.aioli.ec-m.fr/promos/2024-2025/Alix-Dureault/pok/temps-3/"><meta name="description" content="Un POK traitant d&#39;un sujet."><meta property="og:description" content="Un POK traitant d&#39;un sujet."><meta name="twitter:description" content="Un POK traitant d&#39;un sujet."><meta name="author" content="Alix Dur√©ault"><meta name="keywords" content="do-it, centrale, centrale m√©diterran√©e, ecm, POK"><link rel="icon" href="https://raw.githubusercontent.com/do-it-ecm/do-it/main/src/assets/img/logo/favicon.ico" type="image/x-icon"><link rel="icon" href="https://raw.githubusercontent.com/do-it-ecm/do-it/main/src/assets/img/logo/minimal.png" type="image/png"><link rel="apple-touch-icon" href="https://raw.githubusercontent.com/do-it-ecm/do-it/main/src/assets/img/logo/minimal.png"><link href="/assets/stylesheets/main.css" rel="stylesheet"><meta property="og:title" content="Scraping"><meta property="og:image" content="https://raw.githubusercontent.com/do-it-ecm/do-it/main/src/assets/img/logo/intermediate-text.png"><meta property="og:url" content="https://do-it.aioli.ec-m.fr/promos/2024-2025/Alix-Dureault/pok/temps-3/"><meta property="og:type" content="website"><meta name="twitter:card" content="https://raw.githubusercontent.com/do-it-ecm/do-it/main/src/assets/img/logo/intermediate-text.png"><meta name="twitter:title" content="Scraping"><meta name="twitter:image" content="https://raw.githubusercontent.com/do-it-ecm/do-it/main/src/assets/img/logo/intermediate-text.png"><meta name="twitter:url" content="https://do-it.aioli.ec-m.fr/promos/2024-2025/Alix-Dureault/pok/temps-3/"><title>Scraping</title><link href="https://cdn.jsdelivr.net/npm/prismjs/plugins/toolbar/prism-toolbar.min.css" rel="stylesheet"><link id="prism-theme" href="https://cdn.jsdelivr.net/npm/prismjs/themes/prism-solarizedlight.min.css" rel="stylesheet"><link href="https://cdn.jsdelivr.net/npm/prismjs/plugins/line-numbers/prism-line-numbers.min.css" rel="stylesheet"><script src="https://cdn.jsdelivr.net/npm/mermaid/dist/mermaid.min.js"></script><script defer="">const storedTheme=localStorage.getItem("theme");function loadPrismTheme(e){const t=e?"prism-okaidia.min.css":"prism-solarizedlight.min.css",s=document.createElement("link");s.rel="stylesheet",s.id="prism-theme",s.href=`https://cdn.jsdelivr.net/npm/prismjs/themes/${t}`,s.onload=()=>{Prism.highlightAll()};const m=document.getElementById("prism-theme");m?document.head.replaceChild(s,m):document.head.appendChild(s)}function setMermaidTheme(e){const t=e?"dark":"forest";mermaid.initialize({securityLevel:"loose",theme:t,startOnLoad:!0})}function toggleDarkMode(){const e=document.documentElement.classList.contains("dark"),t=e?"light":"dark";localStorage.setItem("theme",t),document.documentElement.classList.toggle("dark",!e),loadPrismTheme(!e),setMermaidTheme(!e)}storedTheme?document.documentElement.classList.toggle("dark","dark"===storedTheme):document.documentElement.classList.toggle("dark",window.matchMedia("(prefers-color-scheme: dark)").matches);const isDark=document.documentElement.classList.contains("dark");loadPrismTheme(isDark),setMermaidTheme(isDark)</script></head><body data-prismjs-copy="üìã" data-prismjs-copy-error="‚ùå" data-prismjs-copy-success="‚úÖ" data-prismjs-copy-timeout="1000" class="bg-neutral-50 text-neutral-950 dark:bg-neutral-900 dark:text-neutral-50"><header class="fixed top-0 z-50 w-full border-b-2 border-gray-200 bg-white dark:bg-neutral-900 dark:border-neutral-700"><div class="max-w-[1000px] mx-auto px-4"><div class="min-h-[50px] flex justify-between items-center"><a class="mx-2" href="/">Home</a> <button class="hidden sm:block text-neutral-950 dark:text-neutral-50 hover:bg-neutral-700 hover:text-neutral-50 hover:dark:bg-neutral-300 hover:dark:text-neutral-950 transition-colors p-2 rounded-full duration-800 ease-in-out" onclick="toggleDarkMode()"><svg viewBox="0 0 24 24" xmlns="http://www.w3.org/2000/svg" class="h-5 aspect-square fill-none aspect-square stroke-2 dark:hidden stroke-current"><circle cx="12" cy="12" r="5"></circle><path d="M12 2V4" stroke-linecap="round"></path><path d="M12 20V22" stroke-linecap="round"></path><path d="M4 12L2 12" stroke-linecap="round"></path><path d="M22 12L20 12" stroke-linecap="round"></path><path d="M19.7778 4.22266L17.5558 6.25424" stroke-linecap="round"></path><path d="M4.22217 4.22266L6.44418 6.25424" stroke-linecap="round"></path><path d="M6.44434 17.5557L4.22211 19.7779" stroke-linecap="round"></path><path d="M19.7778 19.7773L17.5558 17.5551" stroke-linecap="round"></path></svg> <svg viewBox="0 0 24 24" xmlns="http://www.w3.org/2000/svg" class="h-5 aspect-square fill-none aspect-square stroke-2 stroke-current hidden dark:block"><path d="M3.32031 11.6835C3.32031 16.6541 7.34975 20.6835 12.3203 20.6835C16.1075 20.6835 19.3483 18.3443 20.6768 15.032C19.6402 15.4486 18.5059 15.6834 17.3203 15.6834C12.3497 15.6834 8.32031 11.654 8.32031 6.68342C8.32031 5.50338 8.55165 4.36259 8.96453 3.32996C5.65605 4.66028 3.32031 7.89912 3.32031 11.6835Z" stroke-linecap="round" stroke-linejoin="round"></path></svg></button><div class="flex items-center gap-4 sm:gap-6"><a class="" href="/cs">CS</a> <a class="" href="/pok">POK</a> <a class="" href="/mon">MON</a> <a class="" href="/projets">Projets</a> <a class="hidden sm:block" href="/promos">Promos</a> <a href="/search"><svg class="h-5 aspect-square stroke-neutral-950 dark:stroke-neutral-300 fill-none stroke-2" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path stroke-linecap="round" stroke-linejoin="round" d="M21 21l-5.197-5.197m0 0A7.5 7.5 0 105.196 5.196a7.5 7.5 0 0010.607 10.607z"></path></svg> </a><a class="hidden sm:block" href="https://github.com/do-it-ecm/do-it" target="_blank"><svg class="h-5 aspect-square dark:stroke-neutral-300 dark:fill-neutral-300" role="img" viewBox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><title>GitHub</title><path d="M12 .297c-6.63 0-12 5.373-12 12 0 5.303 3.438 9.8 8.205 11.385.6.113.82-.258.82-.577 0-.285-.01-1.04-.015-2.04-3.338.724-4.042-1.61-4.042-1.61C4.422 18.07 3.633 17.7 3.633 17.7c-1.087-.744.084-.729.084-.729 1.205.084 1.838 1.236 1.838 1.236 1.07 1.835 2.809 1.305 3.495.998.108-.776.417-1.305.76-1.605-2.665-.3-5.466-1.332-5.466-5.93 0-1.31.465-2.38 1.235-3.22-.135-.303-.54-1.523.105-3.176 0 0 1.005-.322 3.3 1.23.96-.267 1.98-.399 3-.405 1.02.006 2.04.138 3 .405 2.28-1.552 3.285-1.23 3.285-1.23.645 1.653.24 2.873.12 3.176.765.84 1.23 1.91 1.23 3.22 0 4.61-2.805 5.625-5.475 5.92.42.36.81 1.096.81 2.22 0 1.606-.015 2.896-.015 3.286 0 .315.21.69.825.57C20.565 22.092 24 17.592 24 12.297c0-6.627-5.373-12-12-12"></path></svg></a></div></div></div></header><main class="mt-[66px] max-w-[1000px] mx-auto px-4" data-pagefind-body=""><article class="relative"><h1 class="mb-1">Scraping</h1><div class="mb-4"><div class="px-4 flex flex-wrap items-center"><div class="font-bold">Tag :</div><ul class="flex flex-wrap overflow-auto not-prose list-none my-1 mx-0 px-1 gap-1" data-pagefind-meta="Tags"><li class="bg-yellow-200 rounded-full px-2 text-neutral-950" data-pagefind-filter="Tags">POK</li></ul><div class="hidden" data-pagefind-meta="Type" aria-hidden="true"><span data-pagefind-filter="Type">POK</span></div></div><div class="px-4 flex flex-wrap items-center"><div class="font-bold">Auteur :</div><ul class="flex flex-wrap not-prose list-none my-1 mx-0 px-1 gap-1" data-pagefind-meta="Auteurs"><li class="bg-blue-200 rounded-full px-2 text-neutral-950" data-pagefind-filter="Auteurs">Alix Dur√©ault</li></ul></div><div class="absolute top-0 right-0"><span class="bg-purple-200 rounded-full px-3 py-1 mt-2 mr-2 text-neutral-950" data-pagefind-filter="Ann√©e">2024-2025</span></div></div><p class="mb-4 text-lg">Un POK traitant d'un sujet.</p><div class="quote relative py-2 drop-shadow rounded rounded-tl-none rounded-bl-none border-solid border-l-8 border-purple-500 bg-purple-100 dark:border-purple-800 dark:bg-purple-950"><svg class="absolute w-7 h-7 pl-1 pt-0.5 pb-0.5 fill-none stroke-2 stroke-purple-500 dark:stroke-purple-800" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path stroke-linecap="round" stroke-linejoin="round" d="M5 19a2 2 0 01-2-2V7a2 2 0 012-2h4l2 2h4a2 2 0 012 2v1M5 19h14a2 2 0 002-2v-5a2 2 0 00-2-2H9a2 2 0 00-2 2v5a2 2 0 01-2 2z"></path></svg><div class="pl-8 mr-8"><a href="/promos/2024-2025/Alix-Dureault/">Alix DUREAULT</a><span class="px-1">/</span><a href="/promos/2024-2025/Alix-Dureault/pok/">POK de Alix Dur√©ault</a><span class="px-1">/</span><a href="/promos/2024-2025/Alix-Dureault/pok/temps-3/">Scraping</a></div></div><div class="quote relative py-2 drop-shadow rounded rounded-tl-none rounded-bl-none border-solid border-l-8 border-pink-500 bg-pink-100 dark:border-pink-800 dark:bg-pink-950"><svg class="absolute w-7 h-7 pl-1 pt-0.5 pb-0.5 fill-none stroke-2 stroke-pink-500 dark:stroke-pink-800" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path stroke-linecap="round" stroke-linejoin="round" d="M12 6.253v13m0-13C10.832 5.477 9.246 5 7.5 5S4.168 5.477 3 6.253v13C4.168 18.477 5.754 18 7.5 18s3.332.477 4.5 1.253m0-13C13.168 5.477 14.754 5 16.5 5c1.747 0 3.332.477 4.5 1.253v13C19.832 18.477 18.247 18 16.5 18c-1.746 0-3.332.477-4.5 1.253"></path></svg><div class="pl-8 mb-2 mr-8"><p><b>Pr√©requis</b></p></div><div class="pl-8 mr-8"><p>Des bases en python sont n√©cessaires pour ce POK. De plus, des bases en HTML et CSS sont pr√©f√©rables pour bien comprendre la structure des pages.</p></div></div><script>let lastScrollYSummary=window.scrollY;function toggleSummarySidebar(){document.getElementById("toc-sidebar").classList.toggle("open")}window.addEventListener("scroll",(()=>{const t=document.getElementById("toc-burger-button"),e=document.getElementById("toc-sidebar"),l=window.scrollY;l<10||l<lastScrollYSummary?t.classList.remove("hidden"):e&&e.classList.contains("open")||t.classList.add("hidden"),lastScrollYSummary=l}))</script><p><button id="toc-burger-button" class="sidebar-burger-button right-2" onclick="toggleSummarySidebar()">‚ò∞</button></p><nav id="toc-sidebar" class="sidebar right-0 border-l-2 translate-x-full 3xl:translate-x-0"><h2>Sommaire</h2><nav class="toc"><ol class="toc-list"><li class="toc-item"><a class="toc-link" href="#t%C3%A2ches">T√¢ches</a><ol class="toc-list"><li class="toc-item"><a class="toc-link" href="#sprints">Sprints</a><ol class="toc-list"><li class="toc-item"><a class="toc-link" href="#sprint-1">Sprint 1</a></li><li class="toc-item"><a class="toc-link" href="#sprint-2">Sprint 2</a></li></ol></li><li class="toc-item"><a class="toc-link" href="#horodatage">Horodatage</a></li></ol></li><li class="toc-item"><a class="toc-link" href="#contenu">Contenu</a><ol class="toc-list"><li class="toc-item"><a class="toc-link" href="#premier-sprint">Premier Sprint</a><ol class="toc-list"><li class="toc-item"><a class="toc-link" href="#le-scraping">Le scraping</a></li><li class="toc-item"><a class="toc-link" href="#l%C3%A9galit%C3%A9-du-scraping">L√©galit√© du scraping</a></li><li class="toc-item"><a class="toc-link" href="#apprendre-le-scraping-de-donn%C3%A9es">Apprendre le scraping de donn√©es</a></li></ol></li><li class="toc-item"><a class="toc-link" href="#second-sprint">Second Sprint</a><ol class="toc-list"><li class="toc-item"><a class="toc-link" href="#etude-du-site-du-labo">Etude du site du labo</a></li><li class="toc-item"><a class="toc-link" href="#algorithme">Algorithme</a></li><li class="toc-item"><a class="toc-link" href="#r%C3%A9cup%C3%A9ration-des-donn%C3%A9es">R√©cup√©ration des donn√©es</a></li><li class="toc-item"><a class="toc-link" href="#mise-en-page">Mise en page</a></li><li class="toc-item"><a class="toc-link" href="#automatisation-du-script-et-durabilit%C3%A9">Automatisation du script et durabilit√©</a></li><li class="toc-item"><a class="toc-link" href="#r%C3%A9sultat-final">R√©sultat final</a></li></ol></li></ol></li></ol></nav></nav><p>Pour mon projet de fili√®re m√©tier, nous r√©alisons un bilan carbone. Pour cette structure, beaucoup d'informations sont disponibles sur leur site web. Ainsi, pour pouvoir faciliter la r√©cup√©ration de donn√©es, j'aimerais apprendre le scraping et comment l'utiliser pour r√©cup√©rer des donn√©es qui sont utilisables et compl√©tables par la suite.</p><h2 id="t%C3%A2ches" tabindex="-1"><a class="header-anchor" href="#t%C3%A2ches"></a> T√¢ches</h2><h3 id="sprints" tabindex="-1"><a class="header-anchor" href="#sprints"></a> Sprints</h3><h4 id="sprint-1" tabindex="-1"><a class="header-anchor" href="#sprint-1"></a> Sprint 1</h4><ul><li>[x] Qu'est ce qu'est r√©ellement le scraping ?</li><li>[x] Apprendre les bases du scraping</li><li>[x] Quelles en sont les limites</li><li>[x] Coder la r√©cup√©ration des donn√©es</li></ul><h4 id="sprint-2" tabindex="-1"><a class="header-anchor" href="#sprint-2"></a> Sprint 2</h4><ul><li>[x] Algorithme de r√©cup√©ration des donn√©es</li><li>[x] Traitement des donn√©es</li><li>[x] Travail sur l'utilisation des donn√©es</li></ul><h3 id="horodatage" tabindex="-1"><a class="header-anchor" href="#horodatage"></a> Horodatage</h3><p>Toutes les s√©ances et le nombre d'heure que l'on y a pass√©.</p><table><thead><tr><th>Date</th><th>Heures pass√©es</th><th>Indications</th></tr></thead><tbody><tr><td>14/01</td><td>30 min</td><td>Lecture des mons pr√©c√©dents sur le sujet et √©tude rapide du site √† scraper</td></tr><tr><td>16/01</td><td>1 h 15</td><td>D√©finition du scraping et recherches sur ces limites</td></tr><tr><td>17/01</td><td>2 h</td><td>Suivi d'une formation sur le scraping</td></tr><tr><td>20/01</td><td>1 h</td><td>Suivi d'une formation sur le scraping</td></tr><tr><td>22/01</td><td>1 h 30</td><td>Suivi d'une formation sur le scraping</td></tr><tr><td>23/01</td><td>1 h 45</td><td>Travail sur le site de l'AMSE et algorithme de scraping</td></tr><tr><td>27/01</td><td>2 h</td><td>Travail sur le site de l'AMSE et algorithme de scraping</td></tr><tr><td>28/02</td><td>1 h 20</td><td>Travail sur le site de l'AMSE et algorithme de scraping</td></tr><tr><td>01/03</td><td>2 h 40</td><td>Travail sur le site de l'AMSE et algorithme de scraping</td></tr><tr><td>02/03</td><td>2 h</td><td>Travail sur le site de l'AMSE et algorithme de scraping</td></tr><tr><td>03/03</td><td>1 h 30</td><td>Travail sur le site de l'AMSE et algorithme de scraping, mise en page des donn√©es et automatisation</td></tr><tr><td>04/03</td><td>2 h 30</td><td>Mise en page des donn√©es et automatisation</td></tr></tbody></table><h2 id="contenu" tabindex="-1"><a class="header-anchor" href="#contenu"></a> Contenu</h2><h3 id="premier-sprint" tabindex="-1"><a class="header-anchor" href="#premier-sprint"></a> Premier Sprint</h3><h4 id="le-scraping" tabindex="-1"><a class="header-anchor" href="#le-scraping"></a> Le scraping</h4><p>Pour comprendre un peut mieux de quoi il en retourne, j‚Äôai commencer par lire l‚Äôarticle de Cloudflare sur le sujet : <a href="https://www.cloudflare.com/fr-fr/learning/bots/what-is-data-scraping/">Qu'est ce que le scrping de donn√©es ?</a>.</p><p>Ainsi, le craping de donn√©es est une technique qui permet, √† l‚Äôaide d‚Äôun programme informatique, d‚Äôextraire des donn√©es d‚Äôun autre programme, g√©n√©ralement celui d‚Äôun site web.</p><p>Il y a trois √©tapes cl√©s au scraping :</p><ol><li>Envoie d‚Äôune requette http GET √† un site web</li><li>Analyse du document HTML re√ßu</li><li>Extraction des donn√©es et conversion dans un certain format</li></ol><p>Le scraping est le plus souvent utilis√© pour r√©cup√©r√© du contenu sp√©cifique d‚Äôun site web, des prix ou encore des contacts.</p><h4 id="l%C3%A9galit%C3%A9-du-scraping" tabindex="-1"><a class="header-anchor" href="#l%C3%A9galit%C3%A9-du-scraping"></a> L√©galit√© du scraping</h4><p>Pour comprendre ce sujet, j‚Äôai lu l‚Äôarticle de datadome : <a href="https://datadome.co/fr/guides-fr/scraping-fr/le-web-scraping-est-il-illegal/">Le web scraping est-il ill√©gal ?</a> et regard√© la vid√© de Fireship : <a href="https://www.youtube.com/watch?v=8GhFmQPZAlo">Am I going to jail for web scraping ?</a>.</p><p>Dans la plupart des pays, le web scraping n‚Äôest pas ill√©gal. Cependant l‚Äôutilisation des donn√©es r√©colt√©es peut √™tre punissable juridiquement. Et il faut rester attentif, certains sites restreignent ou interdisent explicitement le web scraping sur leurs donn√©es.</p><p>Les activit√©s li√©es au webscrping qui sont √† la limite de la l√©galit√© sont les suivantes :</p><ul><li>Se connecter √† un site web et t√©l√©charger des donn√©es</li><li>La collecte de donn√©es personnelles ou des informations sensibles sans consentement</li><li>Le scraping de contenu prot√©g√© par des droits d‚Äôauteur ou propri√©taire sans consentement explicite</li><li>Le scraping des donn√©es √† partir de zones restreintes ou priv√©es d‚Äôun site web</li><li>Revendre ou distribuer les donn√©es r√©cup√©r√©es</li><li>La collecte de donn√©es √† des fins discriminatoires, contraires √† l‚Äô√©thique, ou malveillantes</li><li>Le scraping non autoris√© de sites web ou de bases de donn√©es gouvernementales</li></ul><p>En France, certaines de ces activit√©s sont concern√©s par le RGPD, notamment tout ce qui consiste en la r√©colte de donn√©es personnelles sans consentement explicite.</p><h4 id="apprendre-le-scraping-de-donn%C3%A9es" tabindex="-1"><a class="header-anchor" href="#apprendre-le-scraping-de-donn%C3%A9es"></a> Apprendre le scraping de donn√©es</h4><p>Pour apprendre √† scraper, j‚Äôai utiliser la formation propos√©e par Docstring : <a href="https://www.youtube.com/watch?v=sOAZpHDEdkg">Scraping avec Python : Formation compl√®te 2024</a>.</p><p>Je conseille vivement cette formation, elle est assez compl√®te √† la fois sur les bases th√©oriques du scraping mais elle permet aussi de mettre en valeur les diff√©rentes biblioth√®ques qui peuvent √™tre utiles pour le scraping et d'apprendre petit √† petit les diff√©rentes fonctions importantes √† l'aide d'exemples et d'exercices.</p><h3 id="second-sprint" tabindex="-1"><a class="header-anchor" href="#second-sprint"></a> Second Sprint</h3><p>Le second sprint s'est plus concentr√© autour de l'algorithme, la r√©colte de donn√©e, la mise en page et l'automatisation du script pour r√©utilisation future.</p><h4 id="etude-du-site-du-labo" tabindex="-1"><a class="header-anchor" href="#etude-du-site-du-labo"></a> Etude du site du labo</h4><p>Le but de ce MON √©tait de r√©cup√©rer toutes les donn√©es utilisables qui sont pr√©sentes sur le site de l'AMSE √† propos des diff√©rents s√©minaires utilis√©s. Pour cela, j'ai √©tudi√© la structure du site afin de bien comprendre comment aller chercher les informations √† l'aide de l'outil &quot;Inspecter&quot; du navigateur.</p><p>Le premier d√©fi auquel j'ai du faire face a √©t√© de g√©rer le scroll infini de la page √©v√®nement. En effet, tous les √©v√®nements ne s‚Äôaffiche pas d‚Äôun coup sur la page et il faut scroller pour les afficher, ils ne sont m√™me pas loader dans le code html</p><p>Ce qu‚Äôil se passe sur le site c'est que √† chaque fois que l‚Äôon scroll, c‚Äôest comme si le site cliquait sur le lien de la page suivante et envoyait une requ√™te pour l‚Äôobtenir mais les informations s‚Äôaffichent directement sur la page initiale pour donner une impression de scroll infini. Ce qui me pose probl√®me pour aller r√©cup√©rer d'un coup toutes les donn√©es sur les s√©minaires.</p><p>Pour r√©soudre ce probl√®me, j'ai utilis√© la structure de la page. En effet, le lien de la sous-page suivante est contenu dans le code html de la page, ainsi, je peux le s√©lectionner et envoyer une requ√™te pour cette nouvelle page. Cela marche pour toutes les pages sauf pour la derni√®re qui ne poss√®de pas ce lien. Ainsi, il suffit de faire une fonction qui va chercher ce lien pour chaque page et traiter le cas o√π cette fonction ne peut rien renvoyer.</p><p>Pour cela, j'ai utilis√© la fonction suivante :</p><pre class="language-python line-numbers"><code>

def next_page_url (soup) :
    next_page_link_div = soup.find('li', class_="pager__item").find('a')
    if next_page_link_div == None :
        return (None)
    else :
        next_page_link_half = next_page_link_div['href']
        next_page_full_url = urljoin(url_AMSE,next_page_link_half)
        return(next_page_full_url)


</code></pre><p>A part pour cela, la structure √©tait assez simple. Pour chaque √©v√®nement, il est constitu√© en bloc avec la plupart des information disponibles rapidement dont le lien vers la page de renseignement. En naviguant sur la page de renseignement, je peux facilement r√©cup√©rer quelques informations en plus qu'il me manquait.</p><p>La deuxi√®me grosse difficult√© que j'ai pu rencontrer a √©t√© que en fonction du type d'√©v√®nements, la structure n'est pas excatement la m√™me. Pour g√©rer cela, j'ai r√©cup√©rer le type de s√©minaire pour chacun d'entre eux et en fonction de celui-ci, j'ai tri√© les s√©minaires et suis all√© chercher les informations relatives √† ce type de s√©minaire.</p><h4 id="algorithme" tabindex="-1"><a class="header-anchor" href="#algorithme"></a> Algorithme</h4><p>Pour simplifier mon code, j'ai d√©cid√© de le d√©couper en beaucoup de fonctions diff√©rentes. Cela m'a permis de clarifier le code principal et ainsi de pouvoir le lire rapidement et l'automatiser plus facilement.</p><p>La structure du code est la suivante :</p><ol><li>Requ√™te de la page web</li><li>Lecture de la page : r√©cup√©ration du code HTML pour chaque s√©minaire et du lien de la page suivante</li><li>R√©p√©ter les deux premi√®res √©tapes pour toutes les pages</li><li>Pour chaque s√©minaire et en fonction du type de s√©minaire, r√©cup√©rer les informations correspondantes. Par exemple, le nom de l'intervenant, la date, ...</li></ol><p>J'ai tri√© non seulement les √©v√®nements en fonction de leur type mais j'ai aussi s√©par√© les √©v√®nements en distanciel et les √©v√®nements annul√©s gr√¢ce aux tags qu'ils avaient en plus.</p><h4 id="r%C3%A9cup%C3%A9ration-des-donn%C3%A9es" tabindex="-1"><a class="header-anchor" href="#r%C3%A9cup%C3%A9ration-des-donn%C3%A9es"></a> R√©cup√©ration des donn√©es</h4><p>Pour r√©cup√©rer les donn√©es, j'ai utilis√© la biblioth√®que BeautifulSoup. Celle-ci m'a permis avec les fonctions <code>.find</code>, <code>.find-all</code>, <code>.text</code> et <code>.strip()</code> et je me suis raccroch√©e aux diff√©rentes balises comme je le pouvais.</p><p>Malheuresement, la structure du site avait peut d'identifiant unique ou de balise unique. J'ai donc du √™tre assez pr√©cise dans mes rattachements afin de ne pas viser des balises <code>&lt;div&gt;</code> dont la class serait la m√™me.</p><h4 id="mise-en-page" tabindex="-1"><a class="header-anchor" href="#mise-en-page"></a> Mise en page</h4><p>Pour mettre en page les donn√©es que j'ai pu r√©cup√©rer, j'ai utilis√© la biblioth√®que openpyxl.</p><p>Cette fonction m'a permis d'√©crire, √† partir du nom du fichier excel et de ces onglets, les informations importantes avec une certaine mise en forme.</p><p>Pour faciliter la lecture de l'excel et son exploitation, je me suis concentr√©e sur l'√©criture des informations dans diff√©rents onglets en fonction du type de s√©minaire.</p><h4 id="automatisation-du-script-et-durabilit%C3%A9" tabindex="-1"><a class="header-anchor" href="#automatisation-du-script-et-durabilit%C3%A9"></a> Automatisation du script et durabilit√©</h4><p>Le but de cet exercice est de r√©aliser et faciliter un bilan carbone. Ainsi, mon but est aussi de cr√©er un outil qui soit durable dans le temps et utilisable pour des bilans carbone au fur et √† mesure des ann√©es. Pour cela, j'ai mis en place quelques petites modifications pour le permettre.</p><p>Dans un premier temps, j'ai ajouter de la r√©cup√©ration d'information dans l'excel. Ainsi, dans une feuille &quot;Inputs&quot;, la personne souhaitant scrapper les donn√©es peut changer le lien de la page √† scrapper. Elle doit quand m√™me toujours respecter la structure pour que tout fonctionne mais comme cela on peut changer l'ann√©e √† scrapper.</p><p>Pour pouvoir √©crire dans l'excel, il faut que celui-ci soit fermer. De plus, pour faire face √† la modification humaine, j'ai ajout√© quelques fonctions de v√©rification. Lorsque l'on lance le programme, une premi√®re fonction v√©rifie que le fichier ne soit pas ouvert. S'il l'est on arr√™te le code en renvoyant un message demandant de le fermer. De plus, une fonction se charge de v√©rifier si jamais les feuilles que l'on appelle sont toujours l√† et de renvoyer un message si ce n'est pas le cas.</p><p>Enfin, la r√©cup√©ration des donn√©es ne sera pas forc√©ment faite une fois par an mais parfois √† des intervalles plus r√©guliers. Ainsi, j'ai voulu ajouter une fonction qui v√©rifie les dates et en les comparant √† celles donn√©es dans l'excel inclue ou non le s√©minaire dans la liste. Cela permet de faire moins de requ√™tes et d'all√©ger le temps d'ex√©cution du programme.</p><p>Pour la suite et finir ce projet, mon but va √™tre de pr√©parer une notice √† deux niveaux. Cette notice aura pour premier but de montrer les √©tapes et les obligations pour pouvoir ex√©cuter le programme sans soucis. J'aimerais aussi inclure dans cette notice une rapide explication du programme et des fonctions afin que si il doit √™tre revu ou corriger suite √† une modification du texte, cela soit faciliter.</p><h4 id="r%C3%A9sultat-final" tabindex="-1"><a class="header-anchor" href="#r%C3%A9sultat-final"></a> R√©sultat final</h4><p>Le code produit est disponible sur le lien suivant :</p><p><a href="https://github.com/AlixDureault/Scraping-pour-bilan-carbone">Github des exercices et du projet</a></p><p>La page pour les s√©minaires donne ceci :</p><p><img src="https://raw.githubusercontent.com/do-it-ecm/promo-2024-2025/refs/heads/main//Alix-Dureault/pok/temps-3/Resultat.jpg" alt="R√©sultat final du scraping de donn√©es"></p></article></main><footer class="min-h-[50px] border-t-2 mt-4 border-gray-200 dark:border-neutral-700"><div class="max-w-[1000px] mx-auto px-4"><div class="min-h-[50px] flex justify-center items-center"><p class="text-center">¬©2025 <b><span style="font-family:Consolas,sans-serif">Do-<span style="color:#4a86e8">It</span></span></b> - D√©veloppement, Management et Gestion de projets en IT</p></div></div></footer><script src="https://cdn.jsdelivr.net/npm/mathjax/es5/tex-svg-full.js" defer="">window.MathJax={tex:{inlineMath:[["$","$"],["\\(","\\)"]],displayMath:[["$$","$$"],["\\[","\\]"]]},svg:{fontCache:"global"}},document.addEventListener("DOMContentLoaded",(()=>{MathJax.typeset()}))</script><script src="https://cdn.jsdelivr.net/npm/prismjs/prism.min.js"></script><script src="https://cdn.jsdelivr.net/npm/prismjs/plugins/toolbar/prism-toolbar.min.js"></script><script src="https://cdn.jsdelivr.net/npm/prismjs/plugins/line-numbers/prism-line-numbers.min.js"></script><script src="https://cdn.jsdelivr.net/npm/prismjs/plugins/copy-to-clipboard/prism-copy-to-clipboard.min.js"></script><script src="https://cdn.jsdelivr.net/npm/prismjs/plugins/normalize-whitespace/prism-normalize-whitespace.min.js">Prism.plugins.NormalizeWhitespace.setDefaults({"remove-trailing":!0,"remove-indent":!0,"left-trim":!0,"right-trim":!0})</script><script src="https://cdn.jsdelivr.net/npm/prismjs/plugins/show-language/prism-show-language.min.js"></script><script src="https://cdn.jsdelivr.net/npm/prismjs/plugins/autoloader/prism-autoloader.min.js"></script></body></html>