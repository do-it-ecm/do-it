<!doctype html><html lang="fr"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width,initial-scale=1"><meta name="robots" content="index, follow"><link rel="canonical" href="https://do-it.aioli.ec-m.fr/promos/2023-2024/Omar-Salame/mon/temps-4.1/"><meta name="description" content="L&#39;IA g√©n√©rative est de plus en plus palpable dans le paysage technologique actuel. Les grands mod√®les de langage ont ouvert de nouvelles perspectives et suscit√© un vif int√©r√™t dans divers domaines professionnels."><meta property="og:description" content="L&#39;IA g√©n√©rative est de plus en plus palpable dans le paysage technologique actuel. Les grands mod√®les de langage ont ouvert de nouvelles perspectives et suscit√© un vif int√©r√™t dans divers domaines professionnels."><meta name="twitter:description" content="L&#39;IA g√©n√©rative est de plus en plus palpable dans le paysage technologique actuel. Les grands mod√®les de langage ont ouvert de nouvelles perspectives et suscit√© un vif int√©r√™t dans divers domaines professionnels."><meta name="author" content="Omar Salame"><meta name="keywords" content="do-it, centrale, centrale m√©diterran√©e, ecm, MON"><link rel="icon" href="https://raw.githubusercontent.com/do-it-ecm/do-it/main/src/assets/img/logo/favicon.ico" type="image/x-icon"><link rel="icon" href="https://raw.githubusercontent.com/do-it-ecm/do-it/main/src/assets/img/logo/minimal.png" type="image/png"><link rel="apple-touch-icon" href="https://raw.githubusercontent.com/do-it-ecm/do-it/main/src/assets/img/logo/minimal.png"><link href="/assets/stylesheets/main.css" rel="stylesheet"><meta property="og:title" content="Introduction √† l&#39;IA g√©n√©rative"><meta property="og:image" content="https://raw.githubusercontent.com/do-it-ecm/do-it/main/src/assets/img/logo/intermediate-text.png"><meta property="og:url" content="https://do-it.aioli.ec-m.fr/promos/2023-2024/Omar-Salame/mon/temps-4.1/"><meta property="og:type" content="website"><meta name="twitter:card" content="https://raw.githubusercontent.com/do-it-ecm/do-it/main/src/assets/img/logo/intermediate-text.png"><meta name="twitter:title" content="Introduction √† l&#39;IA g√©n√©rative"><meta name="twitter:image" content="https://raw.githubusercontent.com/do-it-ecm/do-it/main/src/assets/img/logo/intermediate-text.png"><meta name="twitter:url" content="https://do-it.aioli.ec-m.fr/promos/2023-2024/Omar-Salame/mon/temps-4.1/"><title>Introduction √† l&#39;IA g√©n√©rative</title><link href="https://cdn.jsdelivr.net/npm/prismjs/plugins/toolbar/prism-toolbar.min.css" rel="stylesheet"><link id="prism-theme" href="https://cdn.jsdelivr.net/npm/prismjs/themes/prism-solarizedlight.min.css" rel="stylesheet"><link href="https://cdn.jsdelivr.net/npm/prismjs/plugins/line-numbers/prism-line-numbers.min.css" rel="stylesheet"><script src="https://cdn.jsdelivr.net/npm/mermaid/dist/mermaid.min.js"></script><script defer="">const storedTheme=localStorage.getItem("theme");function loadPrismTheme(e){const t=e?"prism-okaidia.min.css":"prism-solarizedlight.min.css",s=document.createElement("link");s.rel="stylesheet",s.id="prism-theme",s.href=`https://cdn.jsdelivr.net/npm/prismjs/themes/${t}`,s.onload=()=>{Prism.highlightAll()};const m=document.getElementById("prism-theme");m?document.head.replaceChild(s,m):document.head.appendChild(s)}function setMermaidTheme(e){const t=e?"dark":"forest";mermaid.initialize({securityLevel:"loose",theme:t,startOnLoad:!0})}function toggleDarkMode(){const e=document.documentElement.classList.contains("dark"),t=e?"light":"dark";localStorage.setItem("theme",t),document.documentElement.classList.toggle("dark",!e),loadPrismTheme(!e),setMermaidTheme(!e)}storedTheme?document.documentElement.classList.toggle("dark","dark"===storedTheme):document.documentElement.classList.toggle("dark",window.matchMedia("(prefers-color-scheme: dark)").matches);const isDark=document.documentElement.classList.contains("dark");loadPrismTheme(isDark),setMermaidTheme(isDark)</script></head><body data-prismjs-copy="üìã" data-prismjs-copy-error="‚ùå" data-prismjs-copy-success="‚úÖ" data-prismjs-copy-timeout="1000" class="bg-neutral-50 text-neutral-950 dark:bg-neutral-900 dark:text-neutral-50"><header class="fixed top-0 z-50 w-full border-b-2 border-gray-200 bg-white dark:bg-neutral-900 dark:border-neutral-700"><div class="max-w-[1000px] mx-auto px-4"><div class="min-h-[50px] flex justify-between items-center"><a class="mx-2" href="/">Home</a> <button class="hidden sm:block text-neutral-950 dark:text-neutral-50 hover:bg-neutral-700 hover:text-neutral-50 hover:dark:bg-neutral-300 hover:dark:text-neutral-950 transition-colors p-2 rounded-full duration-800 ease-in-out" onclick="toggleDarkMode()"><svg viewBox="0 0 24 24" xmlns="http://www.w3.org/2000/svg" class="h-5 aspect-square fill-none aspect-square stroke-2 dark:hidden stroke-current"><circle cx="12" cy="12" r="5"></circle><path d="M12 2V4" stroke-linecap="round"></path><path d="M12 20V22" stroke-linecap="round"></path><path d="M4 12L2 12" stroke-linecap="round"></path><path d="M22 12L20 12" stroke-linecap="round"></path><path d="M19.7778 4.22266L17.5558 6.25424" stroke-linecap="round"></path><path d="M4.22217 4.22266L6.44418 6.25424" stroke-linecap="round"></path><path d="M6.44434 17.5557L4.22211 19.7779" stroke-linecap="round"></path><path d="M19.7778 19.7773L17.5558 17.5551" stroke-linecap="round"></path></svg> <svg viewBox="0 0 24 24" xmlns="http://www.w3.org/2000/svg" class="h-5 aspect-square fill-none aspect-square stroke-2 stroke-current hidden dark:block"><path d="M3.32031 11.6835C3.32031 16.6541 7.34975 20.6835 12.3203 20.6835C16.1075 20.6835 19.3483 18.3443 20.6768 15.032C19.6402 15.4486 18.5059 15.6834 17.3203 15.6834C12.3497 15.6834 8.32031 11.654 8.32031 6.68342C8.32031 5.50338 8.55165 4.36259 8.96453 3.32996C5.65605 4.66028 3.32031 7.89912 3.32031 11.6835Z" stroke-linecap="round" stroke-linejoin="round"></path></svg></button><div class="flex items-center gap-4 sm:gap-6"><a class="" href="/cs">CS</a> <a class="" href="/pok">POK</a> <a class="" href="/mon">MON</a> <a class="" href="/projets">Projets</a> <a class="hidden sm:block" href="/promos">Promos</a> <a href="/search"><svg class="h-5 aspect-square stroke-neutral-950 dark:stroke-neutral-300 fill-none stroke-2" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path stroke-linecap="round" stroke-linejoin="round" d="M21 21l-5.197-5.197m0 0A7.5 7.5 0 105.196 5.196a7.5 7.5 0 0010.607 10.607z"></path></svg> </a><a class="hidden sm:block" href="https://github.com/do-it-ecm/do-it" target="_blank"><svg class="h-5 aspect-square dark:stroke-neutral-300 dark:fill-neutral-300" role="img" viewBox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><title>GitHub</title><path d="M12 .297c-6.63 0-12 5.373-12 12 0 5.303 3.438 9.8 8.205 11.385.6.113.82-.258.82-.577 0-.285-.01-1.04-.015-2.04-3.338.724-4.042-1.61-4.042-1.61C4.422 18.07 3.633 17.7 3.633 17.7c-1.087-.744.084-.729.084-.729 1.205.084 1.838 1.236 1.838 1.236 1.07 1.835 2.809 1.305 3.495.998.108-.776.417-1.305.76-1.605-2.665-.3-5.466-1.332-5.466-5.93 0-1.31.465-2.38 1.235-3.22-.135-.303-.54-1.523.105-3.176 0 0 1.005-.322 3.3 1.23.96-.267 1.98-.399 3-.405 1.02.006 2.04.138 3 .405 2.28-1.552 3.285-1.23 3.285-1.23.645 1.653.24 2.873.12 3.176.765.84 1.23 1.91 1.23 3.22 0 4.61-2.805 5.625-5.475 5.92.42.36.81 1.096.81 2.22 0 1.606-.015 2.896-.015 3.286 0 .315.21.69.825.57C20.565 22.092 24 17.592 24 12.297c0-6.627-5.373-12-12-12"></path></svg></a></div></div></div></header><main class="mt-[66px] max-w-[1000px] mx-auto px-4" data-pagefind-body=""><article class="relative"><h1 class="mb-1">Introduction √† l&#39;IA g√©n√©rative</h1><div class="mb-4"><div class="px-4 flex flex-wrap items-center"><div class="font-bold">Tag :</div><ul class="flex flex-wrap overflow-auto not-prose list-none my-1 mx-0 px-1 gap-1" data-pagefind-meta="Tags"><li class="bg-yellow-200 rounded-full px-2 text-neutral-950" data-pagefind-filter="Tags">MON</li></ul><div class="hidden" data-pagefind-meta="Type" aria-hidden="true"><span data-pagefind-filter="Type">MON</span></div></div><div class="px-4 flex flex-wrap items-center"><div class="font-bold">Auteur :</div><ul class="flex flex-wrap not-prose list-none my-1 mx-0 px-1 gap-1" data-pagefind-meta="Auteurs"><li class="bg-blue-200 rounded-full px-2 text-neutral-950" data-pagefind-filter="Auteurs">Omar Salame</li></ul></div><div class="absolute top-0 right-0"><span class="bg-purple-200 rounded-full px-3 py-1 mt-2 mr-2 text-neutral-950" data-pagefind-filter="Ann√©e">2023-2024</span></div></div><p class="mb-4 text-lg">L'IA g√©n√©rative est de plus en plus palpable dans le paysage technologique actuel. Les grands mod√®les de langage ont ouvert de nouvelles perspectives et suscit√© un vif int√©r√™t dans divers domaines professionnels.</p><div class="quote relative py-2 drop-shadow rounded rounded-tl-none rounded-bl-none border-solid border-l-8 border-purple-500 bg-purple-100 dark:border-purple-800 dark:bg-purple-950"><svg class="absolute w-7 h-7 pl-1 pt-0.5 pb-0.5 fill-none stroke-2 stroke-purple-500 dark:stroke-purple-800" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path stroke-linecap="round" stroke-linejoin="round" d="M5 19a2 2 0 01-2-2V7a2 2 0 012-2h4l2 2h4a2 2 0 012 2v1M5 19h14a2 2 0 002-2v-5a2 2 0 00-2-2H9a2 2 0 00-2 2v5a2 2 0 01-2 2z"></path></svg><div class="pl-8 mr-8"><a href="/promos/2023-2024/Omar-Salame/">Omar Salame</a><span class="px-1">/</span><a href="/promos/2023-2024/Omar-Salame/mon/">MON de Omar Salame</a><span class="px-1">/</span><a href="/promos/2023-2024/Omar-Salame/mon/temps-4.1/">Introduction √† l&#39;IA g√©n√©rative</a></div></div><h2 id="table-des-mati%C3%A8res" tabindex="-1"><a class="header-anchor" href="#table-des-mati%C3%A8res"></a> Table des mati√®res</h2><ol><li><a href="#section-1">Introduction</a></li><li><a href="#section-2">Transformateurs</a></li><li><a href="#section-3">Pr√©-entra√Ænement des LLM</a></li><li><a href="#section-4">Conclusion</a></li><li><a href="#section-5">Conclusion</a></li></ol><h2 id="introduction" tabindex="-1"><a class="header-anchor" href="#introduction"></a> Introduction <a id="section-1"></a></h2><h3 id="intelligence-artificielle" tabindex="-1"><a class="header-anchor" href="#intelligence-artificielle"></a> Intelligence artificielle</h3><p>L'IA est un terme g√©n√©ral souvent utilis√© pour d√©crire toutes sortes de syst√®mes informatiques avanc√©s. Je pr√©f√®re parler plus pr√©cis√©ment de <em>Machine learning</em>. La majeure partie de ce que nous voyons aujourd'hui dans l'IA est en fait de l'apprentissage automatique : doter les syst√®mes informatiques de la capacit√© d'apprendre √† partir d'exemples. Les machines programm√©es pour apprendre √† partir d'exemples sont appel√©es &quot;r√©seaux neuronaux&quot;. L'une des principales m√©thodes d'apprentissage consiste √† leur donner de nombreux exemples √† partir desquels apprendre, par exemple en leur indiquant le contenu d'une image - c'est ce que nous appelons la classification. Si nous voulons apprendre √† un r√©seau √† reconna√Ætre un √©l√©phant, il faut qu'un humain lui pr√©sente de nombreux exemples de ce √† quoi ressemble un √©l√©phant et qu'il √©tiquette ces photos en cons√©quence. C'est ainsi que le mod√®le apprend √† faire la distinction entre un √©l√©phant et d'autres d√©tails d'une image. Pour explorer tout cela, j'ai choisi de suivre le <a href="https://www.deeplearning.ai/courses/generative-ai-with-llms/">cours de DeepLearning.AI</a></p><div class="quote relative py-2 drop-shadow rounded rounded-tl-none rounded-bl-none border-solid border-l-8 border-cyan-500 bg-cyan-100 dark:border-cyan-800 dark:bg-cyan-950"><svg class="absolute w-7 h-7 pl-1 pt-0.5 pb-0.5 fill-none stroke-2 stroke-cyan-500 dark:stroke-cyan-800" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path stroke-linecap="round" stroke-linejoin="round" d="M9.663 17h4.673M12 3v1m6.364 1.636l-.707.707M21 12h-1M4 12H3m3.343-5.657l-.707-.707m2.828 9.9a5 5 0 117.072 0l-.548.547A3.374 3.374 0 0014 18.469V19a2 2 0 11-4 0v-.531c0-.895-.356-1.754-.988-2.386l-.548-.547z"></path></svg><div class="pl-8 mb-2 mr-8"><p><b>Information</b></p></div><div class="pl-8 mr-8"><p><strong>Fonctionnement des mod√®les linguistiques</strong> Les mod√®les de langage pr√©disent essentiellement le mot qui suit dans une s√©quence de mots. Nous entra√Ænons ces mod√®les sur de grands volumes de texte afin qu'ils comprennent mieux quel mot est susceptible de venir ensuite. L'un des moyens - mais pas le seul - d'am√©liorer un mod√®le de langage consiste √† lui donner plus de &quot;lecture&quot; ou √† l'entra√Æner sur davantage de donn√©es, un peu comme nous apprenons √† partir des documents que nous √©tudions. Si vous commencez √† taper la phrase &quot;Omar a frapp√© un...&quot;, un mod√®le de langage entra√Æn√© sur suffisamment de donn√©es pourrait pr√©dire &quot;Omar a frapp√© un ballon&quot;. S'il n'est pas suffisamment entra√Æn√©, il ne pourra pr√©dire qu'un &quot;objet rond&quot; ou que sa couleur &quot;jaune&quot;. Plus il y a de donn√©es dans l'entra√Ænement du mod√®le de langage, plus celui-ci devient nuanc√© et plus il a de chances de savoir exactement ce que Marie a le plus probablement frapp√©.</p></div></div><h3 id="ia-g%C3%A9n%C3%A9rative" tabindex="-1"><a class="header-anchor" href="#ia-g%C3%A9n%C3%A9rative"></a> IA G√©n√©rative</h3><p>Un mod√®le g√©n√©ratif peut prendre ce qu'il a appris √† partir des exemples qui lui ont √©t√© montr√©s et cr√©er quelque chose d'enti√®rement nouveau sur la base de ces informations. D'o√π le mot &quot;g√©n√©ratif&quot;. Les grands mod√®les de langage (LLM) sont un type d'IA g√©n√©rative puisqu'ils g√©n√®rent de nouvelles combinaisons de texte sous la forme d'un langage √† consonance naturelle. Nous pouvons m√™me construire des mod√®les de langage pour g√©n√©rer d'autres types de r√©sultats, tels que de nouvelles images, du son et m√™me de la vid√©o, comme avec <a href="https://imagen.research.google/">Imagen</a>, <a href="https://google-research.github.io/seanet/audiolm/examples/">AudioLM</a> et <a href="https://sites.research.google/phenaki/">Phenaki</a>.</p><h2 id="transformateurs" tabindex="-1"><a class="header-anchor" href="#transformateurs"></a> Transformateurs<a id="section-2"></a></h2><p>Avant l'√©mergence des transformateurs, les mod√®les de langage g√©n√©ratifs utilisaient principalement des r√©seaux neuronaux r√©currents (RNN). Cependant, malgr√© leur puissance √† l'√©poque, les RNN √©taient limit√©s par leur capacit√© √† traiter efficacement les d√©pendances √† long terme dans les donn√©es textuelles, ainsi que par leur besoin de ressources computationnelles consid√©rables pour g√©rer des t√¢ches g√©n√©ratives complexes. Prenons l'exemple d'une t√¢che simple de pr√©diction du prochain mot : les RNN peinaient √† fournir des pr√©dictions pr√©cises, m√™me en ayant acc√®s √† plusieurs mots pr√©c√©dents dans la s√©quence. Cette limitation √©tait principalement due √† la nature s√©quentielle du traitement des donn√©es par les RNN, qui les emp√™chait de capturer efficacement les relations √† long terme dans le texte. L'arriv√©e de l'architecture des transformateurs a marqu√© un tournant majeur dans le domaine de l'IA g√©n√©rative. Bas√©e sur le concept d'attention, cette approche novatrice a permis de surmonter les limitations des RNN en offrant une capacit√© d'apprentissage parall√®le et une meilleure prise en compte du contexte global des donn√©es. Les transformateurs peuvent efficacement traiter des s√©quences de donn√©es de longueur variable et apprendre √† pr√™ter attention aux parties importantes du texte, ce qui leur permet de g√©n√©rer des r√©sultats de meilleure qualit√© dans une vari√©t√© de t√¢ches g√©n√©ratives, telles que la traduction automatique et la g√©n√©ration de texte. <img src="https://raw.githubusercontent.com/do-it-ecm/promo-2023-2024/refs/heads/main//Omar-Salame/mon/temps-4.1/transformers.png" width="300" height="500"> *<a href="https://arxiv.org/pdf/1706.03762.pdf">Attention is all you need</a></p><h2 id="le-cycle-de-vie-d'un-projet-ia-g%C3%A9n%C3%A9rative" tabindex="-1"><a class="header-anchor" href="#le-cycle-de-vie-d'un-projet-ia-g%C3%A9n%C3%A9rative"></a> Le cycle de vie d'un projet IA g√©n√©rative<a id="section-3"></a></h2><ul><li><strong>D√©finition du p√©rim√®tre du projet</strong> : Clarifier les objectifs et les fonctionnalit√©s attendues de l'application g√©n√©r√©e par l'IA.</li><li><strong>Choix du mod√®le</strong> : D√©cider d'utiliser un mod√®le existant ou de former un nouveau mod√®le en fonction des besoins sp√©cifiques du projet.</li><li><strong>√âvaluation et entra√Ænement du mod√®le</strong>: Tester les performances du mod√®le et effectuer des ajustements si n√©cessaire pour am√©liorer sa pr√©cision.</li><li><strong>Adaptation et alignement</strong> : S'assurer que le mod√®le g√©n√©r√© par l'IA est conforme aux pr√©f√©rences humaines et aux exigences de d√©ploiement.</li><li><strong>D√©ploiement et int√©gration</strong> : Mettre en ≈ìuvre le mod√®le dans l'infrastructure de l'application et l'int√©grer avec les autres composants du syst√®me.</li><li><strong>Optimisation et consid√©rations suppl√©mentaires</strong> : Optimiser le mod√®le pour le d√©ploiement et prendre en compte toute infrastructure suppl√©mentaire n√©cessaire pour surmonter les limitations potentielles des mod√®les g√©n√©ratifs. Ce processus est it√©ratif et n√©cessite une √©valuation continue pour assurer le succ√®s du projet IA g√©n√©rative.</li></ul><h2 id="pr%C3%A9-entra%C3%AEnement-des-llm" tabindex="-1"><a class="header-anchor" href="#pr%C3%A9-entra%C3%AEnement-des-llm"></a> Pr√©-entra√Ænement des LLM<a id="section-4"></a></h2><p>Avant de commencer le processus, vous devez d√©finir votre cas d'utilisation et choisir entre travailler avec un mod√®le existant ou en cr√©er un nouveau. En g√©n√©ral, on utilise un mod√®le existant. De nombreux mod√®les open-source sont disponibles via des plateformes telles que Hugging Face et PyTorch, avec des fiches descriptives pour chaque mod√®le. Ces mod√®les peuvent √™tre class√©s en trois cat√©gories : auto-encodeurs, mod√®les auto-r√©gressifs et mod√®les s√©quence-s√©quence. Les auto-encodeurs sont entra√Æn√©s √† l'aide de la mod√©lisation de langage masqu√©e, les mod√®les auto-r√©gressifs utilisent la mod√©lisation de langage causale, tandis que les mod√®les s√©quence-s√©quence combinent les deux approches. Les mod√®les plus grands ont tendance √† mieux fonctionner, mais leur entra√Ænement est co√ªteux en ressources. Cette √©volution vers des mod√®les plus grands a √©t√© soutenue par des avanc√©es dans l'architecture des transformers, l'acc√®s √† de grandes quantit√©s de donn√©es et l'am√©lioration des ressources informatiques.</p><h2 id="d%C3%A9fis-calculatoires-du-training-des-llm" tabindex="-1"><a class="header-anchor" href="#d%C3%A9fis-calculatoires-du-training-des-llm"></a> D√©fis calculatoires du training des LLM<a id="section-5"></a></h2><p>L'un des probl√®mes les plus courants lors de l'entra√Ænement de grands mod√®les de langage est de manquer de m√©moire. Les GPUs Nvidia utilisent CUDA pour acc√©l√©rer les op√©rations de deep learning, mais les mod√®les LLM n√©cessitent √©norm√©ment de m√©moire pour stocker tous leurs param√®tres. Pour avoir une id√©e de l'√©chelle du probl√®me, consid√©rons qu'un seul param√®tre est g√©n√©ralement repr√©sent√© par un nombre flottant sur 32 bits, n√©cessitant 4 octets de m√©moire. Pour stocker un milliard de param√®tres, vous auriez besoin de 4 gigaoctets de m√©moire GPU. Cependant, lors de l'entra√Ænement, d'autres composants utilisent √©galement la m√©moire GPU, ce qui augmente consid√©rablement les exigences. Par exemple, pour entra√Æner un mod√®le d'un milliard de param√®tres, vous auriez besoin d'environ 24 gigaoctets de m√©moire GPU. Pour r√©duire la m√©moire requise pour l'entra√Ænement, une technique appel√©e quantification peut √™tre utilis√©e. Elle r√©duit la pr√©cision des poids du mod√®le de 32 bits √† 16 bits ou m√™me √† 8 bits. Par exemple, la quantification en FP16 r√©duit la m√©moire requise de moiti√©, car un nombre en FP16 n√©cessite seulement 2 octets, tandis qu'en FP32, il en faut 4. BFLOAT16, d√©velopp√© par Google Brain, est devenu populaire car il maintient la gamme dynamique du FP32 tout en r√©duisant la m√©moire de moiti√©. Quant √† l'entra√Ænement de mod√®les sur plusieurs GPUs, cela devient essentiel lorsque les mod√®les d√©passent quelques milliards de param√®tres, car un seul GPU ne suffit plus. Cependant, cela n√©cessite un mat√©riel co√ªteux et compliqu√©. En g√©n√©ral, vous ne formerez pas votre propre mod√®le √† partir de z√©ro, mais plut√¥t vous vous appuierez sur des mod√®les pr√©-entra√Æn√©s que vous finirez par affiner pour votre cas d'utilisation sp√©cifique.</p></article></main><footer class="min-h-[50px] border-t-2 mt-4 border-gray-200 dark:border-neutral-700"><div class="max-w-[1000px] mx-auto px-4"><div class="min-h-[50px] flex justify-center items-center"><p class="text-center">¬©2025 <b><span style="font-family:Consolas,sans-serif">Do-<span style="color:#4a86e8">It</span></span></b> - D√©veloppement, Management et Gestion de projets en IT</p></div></div></footer><script src="https://cdn.jsdelivr.net/npm/mathjax/es5/tex-svg-full.js" defer="">window.MathJax={tex:{inlineMath:[["$","$"],["\\(","\\)"]],displayMath:[["$$","$$"],["\\[","\\]"]]},svg:{fontCache:"global"}},document.addEventListener("DOMContentLoaded",(()=>{MathJax.typeset()}))</script><script src="https://cdn.jsdelivr.net/npm/prismjs/prism.min.js"></script><script src="https://cdn.jsdelivr.net/npm/prismjs/plugins/toolbar/prism-toolbar.min.js"></script><script src="https://cdn.jsdelivr.net/npm/prismjs/plugins/line-numbers/prism-line-numbers.min.js"></script><script src="https://cdn.jsdelivr.net/npm/prismjs/plugins/copy-to-clipboard/prism-copy-to-clipboard.min.js"></script><script src="https://cdn.jsdelivr.net/npm/prismjs/plugins/normalize-whitespace/prism-normalize-whitespace.min.js">Prism.plugins.NormalizeWhitespace.setDefaults({"remove-trailing":!0,"remove-indent":!0,"left-trim":!0,"right-trim":!0})</script><script src="https://cdn.jsdelivr.net/npm/prismjs/plugins/show-language/prism-show-language.min.js"></script><script src="https://cdn.jsdelivr.net/npm/prismjs/plugins/autoloader/prism-autoloader.min.js"></script></body></html>