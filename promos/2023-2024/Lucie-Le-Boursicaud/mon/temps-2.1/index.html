<!doctype html><html lang="fr"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width,initial-scale=1"><meta name="robots" content="index, follow"><link rel="canonical" href="https://do-it.aioli.ec-m.fr/promos/2023-2024/Lucie-Le-Boursicaud/mon/temps-2.1/"><meta name="description" content="Ce MON a pour objectif de se familiariser un peu plus avec l&#39;IA et le Machine Learning, d&#39;en comprendre les concept et de faire de petits exercices d&#39;application √† l&#39;aide de Kaggle. "><meta property="og:description" content="Ce MON a pour objectif de se familiariser un peu plus avec l&#39;IA et le Machine Learning, d&#39;en comprendre les concept et de faire de petits exercices d&#39;application √† l&#39;aide de Kaggle. "><meta name="twitter:description" content="Ce MON a pour objectif de se familiariser un peu plus avec l&#39;IA et le Machine Learning, d&#39;en comprendre les concept et de faire de petits exercices d&#39;application √† l&#39;aide de Kaggle. "><meta name="author" content="Lucie Le Boursicaud"><meta name="keywords" content="do-it, centrale, centrale m√©diterran√©e, ecm, MON, Intelligence Artificielle, Machine Learning, D√©couverte, Kaggle"><link rel="icon" href="https://raw.githubusercontent.com/do-it-ecm/do-it/main/src/assets/img/logo/favicon.ico" type="image/x-icon"><link rel="icon" href="https://raw.githubusercontent.com/do-it-ecm/do-it/main/src/assets/img/logo/minimal.png" type="image/png"><link rel="apple-touch-icon" href="https://raw.githubusercontent.com/do-it-ecm/do-it/main/src/assets/img/logo/minimal.png"><link href="/assets/stylesheets/main.css" rel="stylesheet"><meta property="og:title" content="D√©couverte du fonctionnement du Machine Learning"><meta property="og:image" content="https://raw.githubusercontent.com/do-it-ecm/do-it/main/src/assets/img/logo/intermediate-text.png"><meta property="og:url" content="https://do-it.aioli.ec-m.fr/promos/2023-2024/Lucie-Le-Boursicaud/mon/temps-2.1/"><meta property="og:type" content="website"><meta name="twitter:card" content="https://raw.githubusercontent.com/do-it-ecm/do-it/main/src/assets/img/logo/intermediate-text.png"><meta name="twitter:title" content="D√©couverte du fonctionnement du Machine Learning"><meta name="twitter:image" content="https://raw.githubusercontent.com/do-it-ecm/do-it/main/src/assets/img/logo/intermediate-text.png"><meta name="twitter:url" content="https://do-it.aioli.ec-m.fr/promos/2023-2024/Lucie-Le-Boursicaud/mon/temps-2.1/"><title>D√©couverte du fonctionnement du Machine Learning</title><link href="https://cdn.jsdelivr.net/npm/prismjs/plugins/toolbar/prism-toolbar.min.css" rel="stylesheet"><link id="prism-theme" href="https://cdn.jsdelivr.net/npm/prismjs/themes/prism-solarizedlight.min.css" rel="stylesheet"><link href="https://cdn.jsdelivr.net/npm/prismjs/plugins/line-numbers/prism-line-numbers.min.css" rel="stylesheet"><script src="https://cdn.jsdelivr.net/npm/mermaid/dist/mermaid.min.js"></script><script defer="">const storedTheme=localStorage.getItem("theme");function loadPrismTheme(e){const t=e?"prism-okaidia.min.css":"prism-solarizedlight.min.css",s=document.createElement("link");s.rel="stylesheet",s.id="prism-theme",s.href=`https://cdn.jsdelivr.net/npm/prismjs/themes/${t}`,s.onload=()=>{Prism.highlightAll()};const m=document.getElementById("prism-theme");m?document.head.replaceChild(s,m):document.head.appendChild(s)}function setMermaidTheme(e){const t=e?"dark":"forest";mermaid.initialize({securityLevel:"loose",theme:t,startOnLoad:!0})}function toggleDarkMode(){const e=document.documentElement.classList.contains("dark"),t=e?"light":"dark";localStorage.setItem("theme",t),document.documentElement.classList.toggle("dark",!e),loadPrismTheme(!e),setMermaidTheme(!e)}storedTheme?document.documentElement.classList.toggle("dark","dark"===storedTheme):document.documentElement.classList.toggle("dark",window.matchMedia("(prefers-color-scheme: dark)").matches);const isDark=document.documentElement.classList.contains("dark");loadPrismTheme(isDark),setMermaidTheme(isDark)</script></head><body data-prismjs-copy="üìã" data-prismjs-copy-error="‚ùå" data-prismjs-copy-success="‚úÖ" data-prismjs-copy-timeout="1000" class="bg-neutral-50 text-neutral-950 dark:bg-neutral-900 dark:text-neutral-50"><header class="fixed top-0 z-50 w-full border-b-2 border-gray-200 bg-white dark:bg-neutral-900 dark:border-neutral-700"><div class="max-w-[1000px] mx-auto px-4"><div class="min-h-[50px] flex justify-between items-center"><a class="mx-2" href="/">Home</a> <button class="hidden sm:block text-neutral-950 dark:text-neutral-50 hover:bg-neutral-700 hover:text-neutral-50 hover:dark:bg-neutral-300 hover:dark:text-neutral-950 transition-colors p-2 rounded-full duration-800 ease-in-out" onclick="toggleDarkMode()"><svg viewBox="0 0 24 24" xmlns="http://www.w3.org/2000/svg" class="h-5 aspect-square fill-none aspect-square stroke-2 dark:hidden stroke-current"><circle cx="12" cy="12" r="5"></circle><path d="M12 2V4" stroke-linecap="round"></path><path d="M12 20V22" stroke-linecap="round"></path><path d="M4 12L2 12" stroke-linecap="round"></path><path d="M22 12L20 12" stroke-linecap="round"></path><path d="M19.7778 4.22266L17.5558 6.25424" stroke-linecap="round"></path><path d="M4.22217 4.22266L6.44418 6.25424" stroke-linecap="round"></path><path d="M6.44434 17.5557L4.22211 19.7779" stroke-linecap="round"></path><path d="M19.7778 19.7773L17.5558 17.5551" stroke-linecap="round"></path></svg> <svg viewBox="0 0 24 24" xmlns="http://www.w3.org/2000/svg" class="h-5 aspect-square fill-none aspect-square stroke-2 stroke-current hidden dark:block"><path d="M3.32031 11.6835C3.32031 16.6541 7.34975 20.6835 12.3203 20.6835C16.1075 20.6835 19.3483 18.3443 20.6768 15.032C19.6402 15.4486 18.5059 15.6834 17.3203 15.6834C12.3497 15.6834 8.32031 11.654 8.32031 6.68342C8.32031 5.50338 8.55165 4.36259 8.96453 3.32996C5.65605 4.66028 3.32031 7.89912 3.32031 11.6835Z" stroke-linecap="round" stroke-linejoin="round"></path></svg></button><div class="flex items-center gap-4 sm:gap-6"><a class="" href="/cs">CS</a> <a class="" href="/pok">POK</a> <a class="" href="/mon">MON</a> <a class="" href="/projets">Projets</a> <a class="hidden sm:block" href="/promos">Promos</a> <a href="/search"><svg class="h-5 aspect-square stroke-neutral-950 dark:stroke-neutral-300 fill-none stroke-2" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path stroke-linecap="round" stroke-linejoin="round" d="M21 21l-5.197-5.197m0 0A7.5 7.5 0 105.196 5.196a7.5 7.5 0 0010.607 10.607z"></path></svg> </a><a class="hidden sm:block" href="https://github.com/do-it-ecm/do-it" target="_blank"><svg class="h-5 aspect-square dark:stroke-neutral-300 dark:fill-neutral-300" role="img" viewBox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><title>GitHub</title><path d="M12 .297c-6.63 0-12 5.373-12 12 0 5.303 3.438 9.8 8.205 11.385.6.113.82-.258.82-.577 0-.285-.01-1.04-.015-2.04-3.338.724-4.042-1.61-4.042-1.61C4.422 18.07 3.633 17.7 3.633 17.7c-1.087-.744.084-.729.084-.729 1.205.084 1.838 1.236 1.838 1.236 1.07 1.835 2.809 1.305 3.495.998.108-.776.417-1.305.76-1.605-2.665-.3-5.466-1.332-5.466-5.93 0-1.31.465-2.38 1.235-3.22-.135-.303-.54-1.523.105-3.176 0 0 1.005-.322 3.3 1.23.96-.267 1.98-.399 3-.405 1.02.006 2.04.138 3 .405 2.28-1.552 3.285-1.23 3.285-1.23.645 1.653.24 2.873.12 3.176.765.84 1.23 1.91 1.23 3.22 0 4.61-2.805 5.625-5.475 5.92.42.36.81 1.096.81 2.22 0 1.606-.015 2.896-.015 3.286 0 .315.21.69.825.57C20.565 22.092 24 17.592 24 12.297c0-6.627-5.373-12-12-12"></path></svg></a></div></div></div></header><main class="mt-[66px] max-w-[1000px] mx-auto px-4" data-pagefind-body=""><article class="relative"><h1 class="mb-1">D√©couverte du fonctionnement du Machine Learning</h1><div class="mb-4"><div class="px-4 flex flex-wrap items-center"><div class="font-bold">Tags :</div><ul class="flex flex-wrap overflow-auto not-prose list-none my-1 mx-0 px-1 gap-1" data-pagefind-meta="Tags"><li class="bg-yellow-200 rounded-full px-2 text-neutral-950" data-pagefind-filter="Tags">MON</li><li class="bg-yellow-200 rounded-full px-2 text-neutral-950" data-pagefind-filter="Tags">Intelligence Artificielle</li><li class="bg-yellow-200 rounded-full px-2 text-neutral-950" data-pagefind-filter="Tags">Machine Learning</li><li class="bg-yellow-200 rounded-full px-2 text-neutral-950" data-pagefind-filter="Tags">D√©couverte</li><li class="bg-yellow-200 rounded-full px-2 text-neutral-950" data-pagefind-filter="Tags">Kaggle</li></ul><div class="hidden" data-pagefind-meta="Type" aria-hidden="true"><span data-pagefind-filter="Type">MON</span></div></div><div class="px-4 flex flex-wrap items-center"><div class="font-bold">Auteur :</div><ul class="flex flex-wrap not-prose list-none my-1 mx-0 px-1 gap-1" data-pagefind-meta="Auteurs"><li class="bg-blue-200 rounded-full px-2 text-neutral-950" data-pagefind-filter="Auteurs">Lucie Le Boursicaud</li></ul></div><div class="absolute top-0 right-0"><span class="bg-purple-200 rounded-full px-3 py-1 mt-2 mr-2 text-neutral-950" data-pagefind-filter="Ann√©e">2023-2024</span></div></div><p class="mb-4 text-lg">Ce MON a pour objectif de se familiariser un peu plus avec l'IA et le Machine Learning, d'en comprendre les concept et de faire de petits exercices d'application √† l'aide de Kaggle.</p><div class="quote relative py-2 drop-shadow rounded rounded-tl-none rounded-bl-none border-solid border-l-8 border-purple-500 bg-purple-100 dark:border-purple-800 dark:bg-purple-950"><svg class="absolute w-7 h-7 pl-1 pt-0.5 pb-0.5 fill-none stroke-2 stroke-purple-500 dark:stroke-purple-800" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path stroke-linecap="round" stroke-linejoin="round" d="M5 19a2 2 0 01-2-2V7a2 2 0 012-2h4l2 2h4a2 2 0 012 2v1M5 19h14a2 2 0 002-2v-5a2 2 0 00-2-2H9a2 2 0 00-2 2v5a2 2 0 01-2 2z"></path></svg><div class="pl-8 mr-8"><a href="/promos/2023-2024/Lucie-Le-Boursicaud/">Lucie Le Boursicaud</a><span class="px-1">/</span><a href="/promos/2023-2024/Lucie-Le-Boursicaud/mon/">MON de Lucie Le Boursicaud</a><span class="px-1">/</span><a href="/promos/2023-2024/Lucie-Le-Boursicaud/mon/temps-2.1/">D√©couverte du fonctionnement du Machine Learning</a></div></div><div class="quote relative py-2 drop-shadow rounded rounded-tl-none rounded-bl-none border-solid border-l-8 border-pink-500 bg-pink-100 dark:border-pink-800 dark:bg-pink-950"><svg class="absolute w-7 h-7 pl-1 pt-0.5 pb-0.5 fill-none stroke-2 stroke-pink-500 dark:stroke-pink-800" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path stroke-linecap="round" stroke-linejoin="round" d="M12 6.253v13m0-13C10.832 5.477 9.246 5 7.5 5S4.168 5.477 3 6.253v13C4.168 18.477 5.754 18 7.5 18s3.332.477 4.5 1.253m0-13C13.168 5.477 14.754 5 16.5 5c1.747 0 3.332.477 4.5 1.253v13C19.832 18.477 18.247 18 16.5 18c-1.746 0-3.332.477-4.5 1.253"></path></svg><div class="pl-8 mb-2 mr-8"><p>Niveau d√©butant</p></div><div class="pl-8 mr-8"><p>Savoir un peu coder en python.</p></div></div><h3 id="sommaire" tabindex="-1"><a class="header-anchor" href="#sommaire"></a> Sommaire</h3><ol><li>Qu'est-ce que le Machine Learning ?</li><li>D√©but de l'apprentissage avec Kaggle.</li><li>R√©solution de probl√®mes classiques √† l'aide du ML.</li></ol><h3 id="qu'est-ce-que-le-machine-learning" tabindex="-1"><a class="header-anchor" href="#qu'est-ce-que-le-machine-learning"></a> Qu'est-ce que le Machine Learning</h3><p>Le Machine Learning est une sous-discipline de l'intelligence artificielle qui permet le d√©veloppement de techniques permettant aux ordinateurs d'apprendre √† partir de certaines donn√©es. Son objectif principal est de cr√©er des mod√®les capables de g√©n√©raliser des sch√©mas √† partir de donn√©es pass√©es afin de prendre des d√©cisions ou de faire des pr√©dictions sur de nouvelles donn√©es sans √™tre explicitement programm√©s.</p><h5 id="les-diff%C3%A9rentes-%C3%A9tapes" tabindex="-1"><a class="header-anchor" href="#les-diff%C3%A9rentes-%C3%A9tapes"></a> Les diff√©rentes √©tapes</h5><ol><li><strong>Entrainement : </strong>Un mod√®le de Machine Learning est form√© √† l'aide d'un sensemble de donn√©es d'entra√Ænement. Ce jeu de donn√©es est compos√© d'exemples, g√©n√©ralement sous la forme de paires d'entr√©es et de r√©sultats attendus.</li><li><strong>Mod√®le : </strong>Un mod√®le de Machine Learning est une repr√©sentation math√©matique ou statistique qui capture les relations entre les entr√©es eet les sorties dans les donn√©es d'entrainement. Le mod√®le est ajust√© pendant le processus d'entra√Ænement pour minimiser les erreurs entre les pr√©dictions et les r√©sultats r√©els.</li><li><strong>Pr√©diction : </strong>Une fois que le mod√®le a √©t√© entrain√©, il peut √™tre utilis√© pour faire des pr√©dictions sur de nouvelles donn√©es pour lesquelles les r√©sultats ne sont pas connus.</li><li><strong>Evaluation : </strong>Une fois le mod√®le entra√Æn√©, il est √©valuer sur des donn√©es de validations qu'il n'a pas vu avant pour s'assurer de sa capacit√© √† g√©n√©raliser correctement et √† faire des pr√©dictions pr√©cises.</li></ol><h5 id="types-de-machine-learning" tabindex="-1"><a class="header-anchor" href="#types-de-machine-learning"></a> Types de Machine Learning</h5><p>Il existe plusieurs types de Machine Learning :</p><ul><li><strong>Apprentissage supervis√© : </strong>Le mod√®le est form√© sur un ensemble de donn√©es qui contient √† la fois des entr√©es et des r√©sultats attendus. Le mod√®le apprend √† faire des pr√©dictions en se basant sur cette corresponsance entre les entr√©es et les sorties.</li><li><strong>Apprentissage non supervis√© : </strong>Le mod√®le est form√© sur un ensemble de donn√©es qui ne contient que des entr√©es, sans indications sur les r√©sultats attendus. Le mod√®le cherche √† d√©couvrir des structures ou des patterns intrins√®ques aux donn√©es.</li><li><strong>Apprentissage par renforcement : </strong>Le mod√®le apprend √† prendre des d√©cisions en interagissant avec un environnement. Il re√ßoit des r√©compenses ou des p√©nalit√©s en fonction des actions qu'il entreprend, ce qui lui permet d'ajuster son comportement au fil du temps.</li></ul><h5 id="comprendre-le-fonctionnement-du-machine-learning" tabindex="-1"><a class="header-anchor" href="#comprendre-le-fonctionnement-du-machine-learning"></a> Comprendre le fonctionnement du Machine Learning</h5><p>Pour cette partie j'ai surtout regard√© les vid√©os de la cha√Æne <a href="https://www.youtube.com/c/machinelearnia">Machine Learnia</a> au sujet du Machine Learning. J'ai commenc√© par la playlist <a href="https://www.youtube.com/playlist?list=PLO_fdPEVlfKqUF5BPKjGSh7aV9aBshrpY">Initiation au Machine Learning</a> pour continuer avec <a href="https://www.youtube.com/watch?v=82KLS2C_gNQ&amp;list=PLO_fdPEVlfKqMDNmCFzQISI2H_nJcEDJq">Python Sp√©cial Machine Learning</a> √† partir de la 20√®me vid√©o (avant les vid√©os ne concerne pas vraiment le ML mais des biblioth√®ques python tel que Pandas et Matplotlib qui sont important pour traiter le ML).</p><p>Concr√©tement voici comment proc√©d√© lorsque l'on veut faire du Machine Learning avec Python :</p><h5 id="importer-les-biblioth%C3%A8ques-n%C3%A9cessaires" tabindex="-1"><a class="header-anchor" href="#importer-les-biblioth%C3%A8ques-n%C3%A9cessaires"></a> Importer les biblioth√®ques n√©cessaires</h5><p>Avant de commencer, il est n√©cessaire <strong>d'importer les biblioth√®ques n√©cessaires</strong>, y compris scikit-learn pour les algorithmes de machine learning.</p><pre class="language-html line-numbers"><code>

import pandas as pd
import seaborn as sns
import numpy as np
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.model_selection import cross_val_score
from sklearn.neighbors import KNeighborsClassifier


</code></pre><h5 id="charger-les-donn%C3%A9es" tabindex="-1"><a class="header-anchor" href="#charger-les-donn%C3%A9es"></a> Charger les donn√©es</h5><p>Pour avoir avoir acc√®s aux donn√©es on utilise la fonction suivante :</p><pre class="language-html line-numbers"><code>

data = pd.read_csv('chemin/vers/votre/fichier.csv')


</code></pre><h5 id="explorez-les-donn%C3%A9es-pour-mieux-les-comprendre" tabindex="-1"><a class="header-anchor" href="#explorez-les-donn%C3%A9es-pour-mieux-les-comprendre"></a> Explorez les donn√©es pour mieux les comprendre</h5><p>Il est important de connaitre <strong>la structure des donn√©es</strong> que l'on a √† disposition avant de se lancer dans les op√©rations de ML, pour √ßa on utilise ces trois fonctions :</p><pre class="language-html line-numbers"><code>

print(data.head())


</code></pre><p>Cette fonction permt de retrouner les informations suivantes :</p><div stype="display:flex"><img src="https://raw.githubusercontent.com/do-it-ecm/promo-2023-2024/refs/heads/main//Lucie-Le-Boursicaud/mon/temps-2.1/datahead.png"></div><pre class="language-html line-numbers"><code>

print(data.info())


</code></pre><p>Cette fonction permt de retrouner les informations suivantes :</p><div stype="display:flex"><img src="https://raw.githubusercontent.com/do-it-ecm/promo-2023-2024/refs/heads/main//Lucie-Le-Boursicaud/mon/temps-2.1/datainfo.png"></div><pre class="language-html line-numbers"><code>

print(data.describe())


</code></pre><p>Cette fonction permet de retrouner les informations suivantes :</p><div stype="display:flex"><img src="https://raw.githubusercontent.com/do-it-ecm/promo-2023-2024/refs/heads/main//Lucie-Le-Boursicaud/mon/temps-2.1/datadescribes.png"></div><h5 id="traitement-des-donn%C3%A9es" tabindex="-1"><a class="header-anchor" href="#traitement-des-donn%C3%A9es"></a> Traitement des donn√©es</h5><p>Pour ne pas amoindrir l'efficacit√© de notre mod√®le il est important de v√©rifier que les donn√©es ont du sens et d'√©liminer celles dont des informations primordiales manquent ou semble trop extr√™me. Pour cela on utilise la fonction suivante :</p><pre class="language-html line-numbers"><code>

data = data.dropna()


</code></pre><h5 id="s%C3%A9paration-des-donn%C3%A9es" tabindex="-1"><a class="header-anchor" href="#s%C3%A9paration-des-donn%C3%A9es"></a> S√©paration des donn√©es</h5><p>On va diviser les donn√©es en deux ensembles : un ensemble d'entrainement et un ensemble de test.</p><pre class="language-html line-numbers"><code>

X = data.drop('variable_cible', axis=1)
y = data['variable_cible']

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)


</code></pre><p>Une fois que la fonction <em>train_test_split</em> est utilis√©e, elle g√©n√®re deux ensembles distincts : l'ensemble d'entra√Ænement (train) et l'ensemble de test. Ce d√©coupage des donn√©es offre la possibilit√© <strong>d'√©valuer un mod√®le de Machine Learning sous deux perspectives distinctes.</strong></p><p>Initialement, le mod√®le est form√© en utilisant <strong>l'ensemble d'entra√Ænement </strong>fourni par la fonction. Ensuite, ses capacit√©s pr√©dictives sont √©valu√©es en utilisant <strong>l'ensemble de test </strong>√©galement fourni par la fonction. Cette approche permet de tester la performance du mod√®le sur des donn√©es qu'il n'a pas vues pendant l'entra√Ænement, offrant ainsi un aper√ßu de sa g√©n√©ralisation √† de nouvelles donn√©es.</p><h5 id="normalisation%2Fstandardisation-des-donn%C3%A9es" tabindex="-1"><a class="header-anchor" href="#normalisation%2Fstandardisation-des-donn%C3%A9es"></a> Normalisation/Standardisation des donn√©es</h5><p>Cette √©tape n'est pas obligatoire mais elle peut permettre de gagner quelques pourcentage en plus leur de l'√©valuation de notre mod√®le. Elle vise √† mettre toutes les variables (features) des donn√©es sur une √©chelle commune, ce qui peut √™tre particuli√®rement important pour certains algorithmes et mod√®les.</p><pre class="language-html line-numbers"><code>

scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)


</code></pre><p>Globalement normaliser ou standardiser les donn√©es √† pour but de <strong>garantir que le mod√®le utilis√© fonctionne de mani√®re optimale</strong>, en particuli√®re lorsque l'on travaille avec des <strong>algortihmes sensibles aux √©chelles des variables</strong>. Le choix entre la normalisation et la standardisation d√©pend du contaxte sp√©cifique des donn√©es utilis√©es et des exigences associ√©es au mod√®le utilis√©.</p><h5 id="choix-du-mod%C3%A8le" tabindex="-1"><a class="header-anchor" href="#choix-du-mod%C3%A8le"></a> Choix du mod√®le</h5><p>Dans cette √©tape on d√©cide du mod√®le que l'on va utiliser en fonction de nos donn√©es. Les mod√®les de machine learning sont class√©s en diff√©rentes cat√©gories en fonction du type de donn√©es sur lesquelles ils sont appliqu√©s et du type de t√¢che qu'ils accomplissent. On utilise donc pas le m√™me mod√®le pour chaque probl√©matique. Les deux plus simples √† comprendre sont :</p><ul><li>Mod√®les de <strong>R√©gression</strong> : <em>Utilis√©s lorsque la variable cible (output) est continue.</em></li></ul><p>Par exemple on peut utiliser le mod√®le <em>LinearRegression</em> qui permet de mod√©liser la relation lin√©aire entre une variable d√©pendante et une variable ind√©pendante. Il existe aussi des mod√®les de r√©gression lin√©aire multiple, polynomiale et encore bien d'autres...</p><pre class="language-html line-numbers"><code>

from sklearn.linear_model import LinearRegression
model = LinearRegression()


</code></pre><ul><li>Mod√®les de <strong>Classification</strong> : <em>Utilis√©s lorsque la variable cible est une classe ou une cat√©gorie.</em></li></ul><p>Dans cette cat√©gorie de mod√®le on retrouve plusieurs mod√®les. Par exemple le mod√®le <em>KNeighborsClassifier</em> regarde les plus proches voisins (le nombre est d√©terminer en hyperparam√®tre <em>n_neighbors</em>) de l'√©l√©ment qu'il souhaite classer et choisis la cat√©gorie √† la majorit√©. Tandis que le mod√®le <em>RandomForestClassifier</em> fonctionne √† l'aide d'arbre de d√©cision dont les derni√®res feuilles sont les diff√©rentes cat√©gories possibles. Il existe encore tout plein d'autres mod√®le dans la m√™me cat√©gorie mais qui ne fonctionne pas de la m√™me mani√®re et √† chaque probl√®me un mod√®le est plus adapt√© qu'un autre.</p><pre class="language-html line-numbers"><code>


from sklearn.ensemble import RandomForestClassifier
model = RandomForestClassifier()

from sklearn.neighbors import KNeighborsClassifier
model = KNeighborsClassifier(n_neighbors=5)



</code></pre><h5 id="entra%C3%AEnement-du-mod%C3%A8le" tabindex="-1"><a class="header-anchor" href="#entra%C3%AEnement-du-mod%C3%A8le"></a> Entra√Ænement du mod√®le</h5><p>Ici, on va <strong>entrainer notre mod√®le</strong> sur l'ensemble des donn√©es d'entrainements qu'on a d√©terminer lors de la s√©paration des donn√©es. Pour ce faire on utilise la fonction suivante :</p><pre class="language-html line-numbers"><code>

model.fit(X_train, y_train)


</code></pre><h5 id="evaluation-du-mod%C3%A8le" tabindex="-1"><a class="header-anchor" href="#evaluation-du-mod%C3%A8le"></a> Evaluation du mod√®le</h5><p>Une fois notre mod√®le entra√Æn√© on va s'int√©resser √† <strong>ces performances sur des donn√©es qu'il n'a jamais vu </strong>(l'ensemble des donn√©es test). Concr√©tement on veut r√©pondre √† la question &quot;A-t-il bien appris ?&quot;. Pour ce faire on utilise la fonction suivante :</p><pre class="language-html line-numbers"><code>

y_pred = model.predict(X_test)
print("Accuracy:", accuracy_score(y_test, y_pred))
print("Confusion Matrix:\n", confusion_matrix(y_test, y_pred))
print("Classification Report:\n", classification_report(y_test, y_pred))


</code></pre><h5 id="cross-validation" tabindex="-1"><a class="header-anchor" href="#cross-validation"></a> Cross-Validation</h5><p>La Cross-Validation permet de <strong>s'assurer de la stabilit√© du mod√®le</strong>. Elle permet d'√©valuer la performance d'un mod√®le sur un ensemble de donn√©es de mani√®re plus robuste que l'utilisation d'une seule division en ensemble d'entra√Ænement et ensemble de test. Elle aide √† <strong>estimer comment le mod√®le g√©n√©ralise aux donn√©es non vues</strong>. La proc√©dure de validation crois√©e implique de diviser l'ensemble de donn√©es en plusieurs sous-ensembles, puis de former et √©valuer le mod√®le plusieurs fois. Il existe diff√©rentes variantes de la validation crois√©e, la plus courante √©tant la validation crois√©e k-fold. Elle fonctionne de cette fa√ßon :</p><ul><li><strong>Division en k-Folds : </strong>L'ensemble de donn√©es est divis√© en k sous-ensembles (ou &quot;folds&quot;) de taille √©gale.</li><li><strong>It√©rations : </strong>Pour chaque it√©ration, l'un des k sous-ensembles est utilis√© comme ensemble de test, tandis que les k-1 autres sous-ensembles sont utilis√©s comme ensemble d'entra√Ænement.</li><li><strong>Entra√Ænement et √âvaluation : </strong>Le mod√®le est form√© sur l'ensemble d'entra√Ænement et √©valu√© sur l'ensemble de test.</li><li><strong>R√©p√©tition : </strong>Ces √©tapes sont r√©p√©t√©es k fois, chaque sous-ensemble √©tant utilis√© comme ensemble de test exactement une fois.</li><li><strong>Moyenne des Performances : </strong>Les performances (mesures d'√©valuation telles que la pr√©cision, le F-score, etc.) de chaque it√©ration sont g√©n√©ralement moyenn√©es pour obtenir une estimation plus stable et repr√©sentative de la performance du mod√®le.</li></ul><pre class="language-html line-numbers"><code>

cv_scores = cross_val_score(model, X, y, cv=5)
print("Cross-Validation Scores:", cv_scores)
print("Mean CV Score:", cv_scores.mean())


</code></pre><h5 id="optimisation-des-hyperparam%C3%A8tres-du-mod%C3%A8le" tabindex="-1"><a class="header-anchor" href="#optimisation-des-hyperparam%C3%A8tres-du-mod%C3%A8le"></a> Optimisation des hyperparam√®tres du mod√®le</h5><p>On a vu que les mod√®les peuvent avoir des <strong>hyperparram√®tres</strong>. En fonction de leur valeur, le mod√®le est plus ou moins efficace, le but est donc de trouver les hyperparam√®tres optimaux pour que notre mod√®le soit le plus pr√©cis possible. Pour √ßa on utilise la fonction suivante √† adapter en fonction des hyperparam√®tres de notre mod√®le :</p><pre class="language-html line-numbers"><code>

from sklearn.model_selection import GridSearchCV

param_grid = {'n_estimators': [50, 100, 200], 'max_depth': [None, 10, 20]}
grid_search = GridSearchCV(RandomForestClassifier(), param_grid, cv=5)
grid_search.fit(X, y)
best_model = grid_search.best_estimator_


</code></pre><h3 id="apprentissage-avec-kaggle" tabindex="-1"><a class="header-anchor" href="#apprentissage-avec-kaggle"></a> Apprentissage avec Kaggle</h3><p>J'ai tout d'abord suivi le cours <strong><em>Learn Intro to Machine Learning</em></strong> sur la plateforme <a href="https://www.kaggle.com/">Kaggle</a>. Puis je me suis lanc√© dans le challenge <em>House Price Prediction</em> sur ce Jupyter Notebook <a href="MONMachineLearning.ipynb">MON : Machine Learning</a>. J'ai essay√© plusieurs mod√®les d'abord un peu na√Øvement puis en cherchant √† avoir les meilleurs hyperparam√®tres possibles. J'ai obtenue les r√©sultats suivants :</p><table><thead><tr><th>Mod√®le</th><th>Erreur absolue minimale</th></tr></thead><tbody><tr><td>DesicionTreeRegressor</td><td>26322 ‚Ç¨</td></tr><tr><td>RandomForestRegressor</td><td>19655 ‚Ç¨</td></tr><tr><td>GradientBoostingRegressor</td><td>21205 ‚Ç¨</td></tr></tbody></table><p>La moyenne des prix des maisons √©tant de 180 921 ‚Ç¨ la meilleur erreure que j'ai obtenue est d'environ 10.87%. Pour un premier travail sur le Machine Learning c'est une erreur qui me semble correcte m√™me si on peut surement descendre en dessous.</p><h3 id="horodateur" tabindex="-1"><a class="header-anchor" href="#horodateur"></a> Horodateur</h3><table><thead><tr><th>Date</th><th>Heures pass√©es</th><th>Indications</th></tr></thead><tbody><tr><td>Vendredi 17/11</td><td>1H</td><td>Choix des sources/cours √† suivre et d√©but de l'apprentissage</td></tr><tr><td>Dimanche 20/11</td><td>1H</td><td>Kaggle : <em>Learn Intro to Machine Learning</em></td></tr><tr><td>Lundi 21/11</td><td>1H30</td><td>Videos Explicatives de Machine Learnia : <em>Machine Learning Formation Compl√®te</em> Partie 1</td></tr><tr><td>Vendredi 24/11</td><td>2H30</td><td>Videos Explicatives de Machine Learnia : <em>Machine Learning Formation Compl√®te</em> Partie 2 + <em>Python Sp√©cial Machine Learning</em> Vid√©o 20, 21 et 22</td></tr><tr><td>Jeudi 30/11</td><td>3H</td><td>Exercice House Pricing avec diff√©rents mod√®les</td></tr><tr><td>Jeudi 7/11</td><td>2H</td><td>Finalisation House Pricing</td></tr></tbody></table></article></main><footer class="min-h-[50px] border-t-2 mt-4 border-gray-200 dark:border-neutral-700"><div class="max-w-[1000px] mx-auto px-4"><div class="min-h-[50px] flex justify-center items-center"><p class="text-center">¬©2025 <b><span style="font-family:Consolas,sans-serif">Do-<span style="color:#4a86e8">It</span></span></b> - D√©veloppement, Management et Gestion de projets en IT</p></div></div></footer><script src="https://cdn.jsdelivr.net/npm/mathjax/es5/tex-svg-full.js" defer="">window.MathJax={tex:{inlineMath:[["$","$"],["\\(","\\)"]],displayMath:[["$$","$$"],["\\[","\\]"]]},svg:{fontCache:"global"}},document.addEventListener("DOMContentLoaded",(()=>{MathJax.typeset()}))</script><script src="https://cdn.jsdelivr.net/npm/prismjs/prism.min.js"></script><script src="https://cdn.jsdelivr.net/npm/prismjs/plugins/toolbar/prism-toolbar.min.js"></script><script src="https://cdn.jsdelivr.net/npm/prismjs/plugins/line-numbers/prism-line-numbers.min.js"></script><script src="https://cdn.jsdelivr.net/npm/prismjs/plugins/copy-to-clipboard/prism-copy-to-clipboard.min.js"></script><script src="https://cdn.jsdelivr.net/npm/prismjs/plugins/normalize-whitespace/prism-normalize-whitespace.min.js">Prism.plugins.NormalizeWhitespace.setDefaults({"remove-trailing":!0,"remove-indent":!0,"left-trim":!0,"right-trim":!0})</script><script src="https://cdn.jsdelivr.net/npm/prismjs/plugins/show-language/prism-show-language.min.js"></script><script src="https://cdn.jsdelivr.net/npm/prismjs/plugins/autoloader/prism-autoloader.min.js"></script></body></html>